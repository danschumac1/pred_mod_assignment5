{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52a518a",
   "metadata": {},
   "source": [
    "# ISLP Ch. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695401b2",
   "metadata": {},
   "source": [
    "##### SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0280bcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from ISLP.models import (\n",
    "    Stepwise,\n",
    "    sklearn_selected,\n",
    "    sklearn_selection_path\n",
    ")\n",
    "\n",
    "from l0bnb import fit_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590057b",
   "metadata": {},
   "source": [
    "## 2. For parts (a) through (c), indicate which of i. through iv. is correct. Justify your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeb24d",
   "metadata": {},
   "source": [
    "- i. More flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n",
    "- ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.\n",
    "- iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n",
    "- iv. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d09ef",
   "metadata": {},
   "source": [
    "### (a) The lasso, relative to least squares, is:\n",
    "- iii, less flexible. Improved accuracy when increase in bias is < its decrease in variance\n",
    "\n",
    "    - Due to regularization, Lasso is less flexible than lease squares.this is because lasso has a term that penilizes the model for having more predictors. If the variables are penilized harshly enough, it can increase bias (more general model) and decrease variance (if seeing different training data, get similar results.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd19a3",
   "metadata": {},
   "source": [
    "### (b) Ridge regression relative to least squares.\n",
    "- also iii, for more or less the same reasons.\n",
    "    - Ridge just uses a different shink function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6723d",
   "metadata": {},
   "source": [
    "### (c) Non-linear methods relative to least squares\n",
    "\n",
    "- ii, more flex. improved accuracy when increase in variance is less than its decrease in bias\n",
    "- With non linear methods we don't make assumptions about the shape. So, if the actual shape of ___f___ is non-linear, we will decrease bias (it will be less general now) and increase variance (new data = very dif model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46054d18",
   "metadata": {},
   "source": [
    "## 9. In this exercise, we will predict the number of applications received using the other variables in the College data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b37030",
   "metadata": {},
   "source": [
    "### (a) Split the data set into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0b0dfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data.\n",
    "college = load_data('College')\n",
    "\n",
    "# Save Various MSE as we go.\n",
    "results_list = []\n",
    "\n",
    "# replace '.'s with '_'s in column names so later it will work in formulas\n",
    "for col_og in college.columns:\n",
    "    if '.' in col_og:\n",
    "        col_new = col_og.replace('.', '_')          \n",
    "        college.rename(columns={col_og: col_new}, inplace=True)\n",
    "\n",
    "# get dummy variables rather than text variable\n",
    "college = pd.get_dummies(college, drop_first=True)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(27)\n",
    "\n",
    "# get number of obs in data\n",
    "n_rows = len(college)\n",
    "\n",
    "# get a random 70% percent of the rows\n",
    "train_size = round(n_rows * 0.7)\n",
    "train_index = np.random.choice(\n",
    "    np.arange(n_rows),\n",
    "    train_size,\n",
    "    replace = False\n",
    ")\n",
    "train = college.iloc[train_index]\n",
    "\n",
    "\n",
    "# get the other 30% for testing\n",
    "test_index = np.setdiff1d(np.arange(n_rows), train_index)\n",
    "test = college.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c23d6",
   "metadata": {},
   "source": [
    "### (b) Fit a linear model using least squares on the training set, and report the test error obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00f84697",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Apps   R-squared:                       0.927\n",
      "Model:                            OLS   Adj. R-squared:                  0.925\n",
      "Method:                 Least Squares   F-statistic:                     392.3\n",
      "Date:                Mon, 18 Mar 2024   Prob (F-statistic):          1.05e-285\n",
      "Time:                        17:06:50   Log-Likelihood:                -4578.8\n",
      "No. Observations:                 544   AIC:                             9194.\n",
      "Df Residuals:                     526   BIC:                             9271.\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept    -327.1957    515.187     -0.635      0.526   -1339.272     684.881\n",
      "Accept          1.6649      0.049     33.897      0.000       1.568       1.761\n",
      "Enroll         -1.4297      0.252     -5.676      0.000      -1.924      -0.935\n",
      "Top10perc      62.3813      7.222      8.638      0.000      48.194      76.569\n",
      "Top25perc     -18.5754      5.945     -3.125      0.002     -30.254      -6.897\n",
      "F_Undergrad     0.1287      0.048      2.686      0.007       0.035       0.223\n",
      "P_Undergrad     0.0079      0.053      0.150      0.881      -0.096       0.111\n",
      "Outstate       -0.0809      0.024     -3.385      0.001      -0.128      -0.034\n",
      "Room_Board      0.1783      0.062      2.884      0.004       0.057       0.300\n",
      "Books           0.1277      0.321      0.398      0.691      -0.502       0.758\n",
      "Personal        0.1014      0.086      1.182      0.238      -0.067       0.270\n",
      "PhD           -13.2061      5.996     -2.202      0.028     -24.985      -1.427\n",
      "Terminal       -0.0075      6.471     -0.001      0.999     -12.719      12.704\n",
      "S_F_Ratio       9.9113     16.359      0.606      0.545     -22.225      42.048\n",
      "perc_alumni    -5.0595      5.197     -0.974      0.331     -15.268       5.149\n",
      "Expend          0.0552      0.016      3.390      0.001       0.023       0.087\n",
      "Grad_Rate       8.3792      3.708      2.260      0.024       1.096      15.663\n",
      "Private_Yes  -494.6426    174.336     -2.837      0.005    -837.122    -152.163\n",
      "==============================================================================\n",
      "Omnibus:                      280.045   Durbin-Watson:                   1.909\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3699.507\n",
      "Skew:                           1.931   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.178   Cond. No.                     1.81e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.81e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# formula includes everything but the target\n",
    "formula = 'Apps ~ ' + ' + '.join(train.columns.drop('Apps'))\n",
    "\n",
    "# make the full model\n",
    "model = OLS.from_formula(formula, data = train)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b66dfc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS MSE: 839878.5198035759\n"
     ]
    }
   ],
   "source": [
    "# make predictions using calculated coefecients \n",
    "ols_pred = results.predict(test)\n",
    "\n",
    "# use those preds to calculate MSE\n",
    "ols_mse = np.mean(\n",
    "    (ols_pred - test['Apps']) ** 2\n",
    ")\n",
    "\n",
    "print('OLS MSE:', ols_mse)\n",
    "results_list.append({'OLS', ols_mse})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25095580",
   "metadata": {},
   "source": [
    "### (c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ecef9d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Alpha: 0.01\n",
      "RIDGE MSE: 1492284.513227505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X = college.drop('Apps',axis = 1)\n",
    "Y = college['Apps']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features (fit on training and transform both training and test)\n",
    "scaler = StandardScaler()\n",
    "Xs_train = scaler.fit_transform(X_train)\n",
    "Xs_test = scaler.transform(X_test)\n",
    "\n",
    "# Prepare a range of lambda values for cross-validation\n",
    "# Note: RidgeCV expects alpha values directly, not scaled by Y's std\n",
    "alphas = 10 ** np.linspace(8, -2, 100)\n",
    "\n",
    "# Initialize and fit the RidgeCV model (with alphas and cv specified)\n",
    "ridge_cv = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "ridge_cv.fit(Xs_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = ridge_cv.predict(Xs_test)\n",
    "\n",
    "# Calculate and report the test error (e.g., Mean Squared Error)\n",
    "test_error = mean_squared_error(Y_test, Y_pred)\n",
    "print(f'Chosen Alpha: {ridge_cv.alpha_}')\n",
    "print(f\"RIDGE MSE: {test_error}\")\n",
    "\n",
    "results_list.append({'RIDGE', test_error})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8e501",
   "metadata": {},
   "source": [
    "### (d) Fit a lasso model on the training set, with λ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefficient estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "987a7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO MSE: 1478937.5976541417\n",
      "The chosen alpha (λ) is: 3.7211179211220644\n",
      "Number of non-zero coefficient estimates: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize and fit the LassoCV model\n",
    "lasso_cv = LassoCV(alphas=None, cv=5, max_iter=10000, random_state=42)\n",
    "lasso_cv.fit(Xs_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = lasso_cv.predict(Xs_test)\n",
    "\n",
    "# Calculate and report the test error (e.g., Mean Squared Error)\n",
    "test_error = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"LASSO MSE: {test_error}\")\n",
    "results_list.append({'LASSO', test_error})\n",
    "\n",
    "# Report the chosen alpha (λ)\n",
    "chosen_alpha = lasso_cv.alpha_\n",
    "print(f\"The chosen alpha (λ) is: {chosen_alpha}\")\n",
    "\n",
    "# Count non-zero coefficients\n",
    "non_zero_coefs = np.sum(lasso_cv.coef_ != 0)\n",
    "print(f\"Number of non-zero coefficient estimates: {non_zero_coefs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633caa9",
   "metadata": {},
   "source": [
    "### (e) Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d28da1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components (M) selected by cross-validation: 17\n",
      "PCR MSE with M=17: 1492443.3790390252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as n\n",
    "\n",
    "# Initialize a range for the number of components (M) to test\n",
    "max_components = min(Xs_train.shape)\n",
    "components_range = range(1, max_components + 1)\n",
    "\n",
    "# Record cross-validation scores for each M\n",
    "cv_scores = []\n",
    "\n",
    "for m in components_range:\n",
    "    # Set up the PCA and the linear regression model as a pipeline\n",
    "    pca = PCA(n_components=m)\n",
    "    lr = LinearRegression()\n",
    "    pipeline = Pipeline([('pca', pca), ('linear_regression', lr)])\n",
    "    \n",
    "    # Compute cross-validation score for this number of components\n",
    "    scores = cross_val_score(pipeline, Xs_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Find the number of components with the best cross-validation score\n",
    "M_optimal = components_range[np.argmax(cv_scores)]\n",
    "print(f\"Optimal number of components (M) selected by cross-validation: {M_optimal}\")\n",
    "\n",
    "# Fit the PCR model with the optimal number of components\n",
    "pca_optimal = PCA(n_components=M_optimal)\n",
    "Xs_train_pca = pca_optimal.fit_transform(Xs_train)\n",
    "Xs_test_pca = pca_optimal.transform(Xs_test)\n",
    "lr_optimal = LinearRegression().fit(Xs_train_pca, Y_train)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "Y_pred = lr_optimal.predict(Xs_test_pca)\n",
    "test_error = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"PCR MSE with M={M_optimal}: {test_error}\")\n",
    "results_list.append({'PCR', test_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b77f6b",
   "metadata": {},
   "source": [
    " ### (f) Fit a PLS model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "01b4408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components (M) selected by cross-validation: 15\n",
      "PCR MSE with M=15: 1492522.1275275091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and Y have already been defined\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Cross-validation to select the optimal number of components\n",
    "max_components = min(X_train.shape[0], X_train.shape[1], 15)  # Limit to a reasonable maximum to avoid overfitting\n",
    "cv_scores = []\n",
    "\n",
    "for m in range(1, max_components + 1):\n",
    "    pls = PLSRegression(n_components=m)\n",
    "    scores = cross_val_score(pls, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Select the number of components with the highest cross-validation score (lowest MSE as scores are negative)\n",
    "M_optimal = np.argmax(cv_scores) + 1  # +1 because index 0 corresponds to M=1\n",
    "print(f\"Optimal number of components (M) selected by cross-validation: {M_optimal}\")\n",
    "\n",
    "# Fit the PLS model with the optimal number of components\n",
    "pls_optimal = PLSRegression(n_components=M_optimal)\n",
    "pls_optimal.fit(X_train, Y_train)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "Y_pred = pls_optimal.predict(X_test)\n",
    "test_error = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"PCR MSE with M={M_optimal}: {test_error}\")\n",
    "results_list.append({'PLS', test_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a88baa",
   "metadata": {},
   "source": [
    "### (g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74a25f",
   "metadata": {},
   "source": [
    "- Lasso performed the best. with the lowest MSE\n",
    "- There is a huge difference between OLS and all other methods. OLS performed very badly.\n",
    "- After that though, RIDGE, LASSO, PCR, and PLS performed pretty similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41d38f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{839878.5198035759, 'OLS'},\n",
       " {1492284.513227505, 'RIDGE'},\n",
       " {1478937.5976541417, 'LASSO'},\n",
       " {1492443.3790390252, 'PCR'},\n",
       " {1492522.1275275091, 'PLS'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3c957",
   "metadata": {},
   "source": [
    "## 11. We will now try to predict per capita crime rate in the Boston data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdfd604",
   "metadata": {},
   "source": [
    "### (a) Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe30394",
   "metadata": {},
   "source": [
    "### (b) Propose a model (or set of models) that seem to perform well on this data set, and justify your answer. Make sure that you are evaluating model performance using validation set error, crossvalidation, or some other reasonable alternative, as opposed to using training error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac4f99",
   "metadata": {},
   "source": [
    "### (c) Does your chosen model involve all of the features in the data set? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
